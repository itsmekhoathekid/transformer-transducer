# Transformer Transducer â€” My Implementation

> Implementation of **Transformer Transducer** for end-to-end speech recognition, inspired by the paper:  
> **Self-Attention Transducers for End-to-End Speech Recognition** (2019).  
> ðŸ“„ Paper: https://www.isca-archive.org/interspeech_2019/tian19b_interspeech.pdf

## ðŸ”— Repository
- GitHub: https://github.com/itsmekhoathekid/transformer-transducer

## ðŸš€ Quickstart

### 1) Clone & Setup
```
bash
git clone https://github.com/itsmekhoathekid/transformer-transducer
cd transformer-transducer
```

### 2) Download & Prepare Dataset
This will download the datasets configured inside the script and generate manifests/features as needed.
```
bash
bash ./prep_data.sh
```

### 3) Train
Train with a YAML/JSON config of your choice.
```
bash
python train.py --config path/to/train_config.yaml
```

### 4) Inference (example)
```
bash
python infererence.py --config path/to/train_config.yaml --epoch num_epoch
```

## ðŸ“¦ Project Layout (typical)
```
transformer-transducer/
â”œâ”€â”€ prep_data.sh                 # dataset download & preprocessing
â”œâ”€â”€ train.py                     # training entry point
â”œâ”€â”€ inference.py                     # inference script (optional)
â”œâ”€â”€ configs/                     # training configs (yaml/json)
â”œâ”€â”€ models/                    # model, losses, data, utils
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ encoder.py
â”‚   â”œâ”€â”€ decoder.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ utils/ 
â””â”€â”€ README.md
```

